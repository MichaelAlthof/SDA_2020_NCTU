[<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/banner.png" width="888" alt="Visit QuantNet">](http://quantlet.de/)

## [<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/qloqo.png" alt="Visit QuantNet">](http://quantlet.de/) **web_scraping_sciencedirect** [<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/QN2.png" width="60" alt="Visit QuantNet 2.0">](http://quantlet.de/)

```yaml

Name of Quantlet: web_scraping_sciencedirect

Published in:  SDA_2020_NCTU

Description: scraping on sciencedirect with scrapy, the data will be used to create topic modeling about covid19 based on the abstract

Keywords:
- web crawling
- abstract
- covid19
- sciencedirect
- topic modeling

Author: Muhaimin, Rasyid, Aziz

```

### PYTHON Code
```python

# -*- coding: utf-8 -*-
"""web_scrape_on_sciencedirect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CYMWHROdIEm8mu4ghiTSzROg-EFIQRoN
"""

# Web scraping on sciencedirect using scrapy.
# The purpose of this code is scrape an abstract from the article on sciencedirect.
# There are some keywords that used, especially about covid-19.
# The data will analyze with topic modeling methods.
# Author: aziz, muhaimin

# Install scrapy
!pip install scrapy # This step is required if you don't have scrapy library

# Import library
import scrapy
from scrapy.linkextractors import LinkExtractor
import pandas as pd
import os
import json

# Create a scrapy project called Crawling.
# A folder named Crawling will be created in your device.
# After the created, just change the directory into it

!scrapy startproject Crawling # Type this on command prompt.
!cd Crawling # Type this on command prompt to change the directory
os.chdir('/content/Crawling/') # Type this on python.

# Before start to crawl/scrape from the web. Make sure the spider script already in the folder spiders on '/content/Crawling/Crawling/spiders/'.
# The spider script named sciencedirect.py, the file is exist in the github.
# Moreover, overwrite the items.py script on '/content/Crawling/Crawling/' with the items.py script that exist in the github.
# Then strat scraping

!scrapy crawl scidir -O abstract.json # Type this on command prompt to start scraping

# Convert json to dataframe

abstract_dataframe = pd.json_normalize(data)

# This result (data) will be processing first before analyze using LDA/DTM
```

automatically created on 2020-12-01