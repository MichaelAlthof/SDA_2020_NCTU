[<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/banner.png" width="888" alt="Visit QuantNet">](http://quantlet.de/)

## [<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/qloqo.png" alt="Visit QuantNet">](http://quantlet.de/) **Crawl_cryptocurrencies** [<img src="https://github.com/QuantLet/Styleguide-and-FAQ/blob/master/pictures/QN2.png" width="60" alt="Visit QuantNet 2.0">](http://quantlet.de/)

```yaml

Name of Quantlet: Crawl_cryptocurrencies

Published in:  SDA_2020_NCTU

Description: Crawling cryptocurrencies data from coinmarketcap.com using beautifulsoup library from python language programming, and store it into csv file

Keywords: web crawling, cryptocurrencies, blockchain, CRIX analysis, coinmarketcap

See also: CRIX

Author: Muhaimin 20201107
```

### PYTHON Code
```python

# -*- coding: utf-8 -*-
"""crawl_cryptocurrencies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tLwpVuErgwWR3houJfsN9kwSRCZIf7yt
"""

#import library
from bs4 import BeautifulSoup
import requests
import pandas as pd
import json
import time

#declare the website link
cmc = requests.get('https://coinmarketcap.com/')
soup = BeautifulSoup(cmc.content, 'html.parser')

#check the cryptocurrencies might be available
data = soup.find('script', id="__NEXT_DATA__", type="application/json")
coins = {}
coins_data = json.loads(data.contents[0])
listings = coins_data['props']['initialState']['cryptocurrency']['listingLatest']['data']
for i in listings:
  coins[str(i['id'])] = i['slug']

#begin crawl the data
market_cap = []
volume = []
timestamp = []
name = []
symbol = []
slug = []
price = []
#Set up the date period when we want crawl the data. Caution! The data might be expired or not available yet and made the results empty.
start_date = '20200101' #yyyymmdd
end_date = '20201001' #yyyymmdd
for i in coins:
  url = 'https://coinmarketcap.com/currencies/'+coins[i]+'/historical-data/?start='+str(start_date)+'&end='+str(end_date)
  page = requests.get(url)
  soup = BeautifulSoup(page.content, 'html.parser')
  data = soup.find('script', id="__NEXT_DATA__", type="application/json")
  if not data:
    continue
  historical_data = json.loads(data.contents[0])
  quotes = historical_data['props']['initialState']['cryptocurrency']['ohlcvHistorical'][i]['quotes']
  info = historical_data['props']['initialState']['cryptocurrency']['ohlcvHistorical'][i]
  for j in quotes:
    timestamp.append(j['quote']['USD']['timestamp'])
    price.append(j['quote']['USD']['close'])
    market_cap.append(j['quote']['USD']['market_cap'])
    volume.append(j['quote']['USD']['volume'])
    name.append(info['name'])
    symbol.append(info['symbol'])
    slug.append(coins[i])

#create dataframe  
df = pd.DataFrame(columns=['timestamp', 'price', 'market_cap', 'volume', 'name', 'symbol', 'slug'])
df['price'] = price
df['market_cap'] = market_cap
df['volume'] = volume
df['timestamp'] = timestamp
df['name'] = name
df['symbol'] = symbol
df['slug'] = slug

#preprocess the timestamp
new_timestamp = []
for i in df['timestamp']:
  new_timestamp.append(i[:10])
df['timestamp'] = new_timestamp
 
#save to directory
df = df.pivot(index = "timestamp", columns="symbol", values=["price", "market_cap", "volume"])
df['market_cap'].to_csv('market.csv')
df['price'].to_csv('price.csv')
df['volume'].to_csv('volume.csv')

!python crawl_cryptocurrencies_on_coinmarketcap.py


```

automatically created on 2020-11-18