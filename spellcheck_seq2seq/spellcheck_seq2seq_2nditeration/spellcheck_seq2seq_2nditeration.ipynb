{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.726693Z",
     "start_time": "2020-04-26T13:28:33.958681Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T10:54:09.862245Z",
     "start_time": "2020-04-28T10:54:09.855228Z"
    }
   },
   "outputs": [],
   "source": [
    "def getData(mode):\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    dataset = json.load(open('./data/'+mode+'.json', 'r'))\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for data in dataset:\n",
    "        inputs.append(data['input'])\n",
    "        labels.append(data['target'])\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.777586Z",
     "start_time": "2020-04-26T13:28:34.771625Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self):\n",
    "        self.word2index = {'SOS': 0, 'EOS': 1, 'PAD': 2, 'UNK': 3}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS', 2: 'PAD', 3: 'UNK'}\n",
    "        self.n_words = 4\n",
    "        self.max_length = 0\n",
    "        self.build_vocab(getData('train')[0])\n",
    "        \n",
    "    # input the training data and build vocabulary\n",
    "    def build_vocab(self, corpus):\n",
    "        for words in corpus:\n",
    "            for word in words:\n",
    "                if len(word) > self.max_length:\n",
    "                    self.max_length = len(word)\n",
    "                    \n",
    "                for char in word:\n",
    "                    if char not in self.word2index:\n",
    "                        self.word2index[char] = self.n_words\n",
    "                        self.index2word[self.n_words] = char\n",
    "                        self.n_words += 1                      \n",
    "                    \n",
    "    # convert word to indices\n",
    "    def word2indices(self, word, add_eos=False, add_sos=False):\n",
    "        indices = [self.word2index[char] if char in self.word2index else 3 for char in word]\n",
    "\n",
    "        if add_sos:\n",
    "            indices.insert(0, 0)\n",
    "        if add_eos:\n",
    "            indices.append(1)\n",
    "            \n",
    "        # padding input of same target into same length\n",
    "        indices.extend([2]*(self.max_length-len(word)))     \n",
    "        return np.array(indices)\n",
    "    \n",
    "    # convert indices to word\n",
    "    def indices2word(self, indices):\n",
    "        word = [self.index2word[idx] for idx in indices if idx > 2 ]\n",
    "        return ''.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.795203Z",
     "start_time": "2020-04-26T13:28:34.779015Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  6 12 12 17  2  2  2  2  2  2  2  2  2  2  2  2  2  2]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "v = Vocab()\n",
    "t = \"hello\"\n",
    "idx = v.word2indices(t)\n",
    "print(idx)\n",
    "t = v.indices2word(idx)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.801182Z",
     "start_time": "2020-04-26T13:28:34.796251Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpellingLoader(data.Dataset):\n",
    "    def __init__(self, mode, vocab):\n",
    "        self.mode = mode   \n",
    "        self.inputs, self.targets = self.convert_pair()\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = torch.LongTensor(self.vocab.word2indices(self.inputs[index]))\n",
    "        target = torch.LongTensor(self.vocab.word2indices(self.targets[index]))\n",
    "        return input, target\n",
    "    \n",
    "    # convert (multi-input)+target into multi-(input+target) pair\n",
    "    def convert_pair(self):\n",
    "        input_data, label_data = getData(self.mode)\n",
    "        inputs_list = []\n",
    "        labels_list = []\n",
    "        for inputs, label in zip(input_data, label_data):\n",
    "            for input in inputs:\n",
    "                inputs_list.append(input)\n",
    "                labels_list.append(label)\n",
    "        return inputs_list, labels_list                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.825927Z",
     "start_time": "2020-04-26T13:28:34.802349Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "trainset = SpellingLoader('train', vocab)\n",
    "testset = SpellingLoader('test', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.831102Z",
     "start_time": "2020-04-26T13:28:34.826934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 14, 15, 21, 17, 17, 19,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "          2]),\n",
       " tensor([ 6,  4, 14, 15, 21, 17, 17, 19,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "          2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.836358Z",
     "start_time": "2020-04-26T13:28:34.832191Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, -1, self.hidden_size)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size=64):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:28:34.842513Z",
     "start_time": "2020-04-26T13:28:34.837555Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, -1, self.hidden_size)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size=64):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
